# === Step 1: Install Required Libraries ===
!pip install kaggle
!pip install pandas numpy scikit-learn matplotlib seaborn

# === Step 2: Upload Your Kaggle API Key ===
from google.colab import files
files.upload()  # Upload kaggle.json here

# === Step 3: Setup Kaggle API Credentials ===
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# === Step 4: Download the House Prices Dataset ===
!kaggle competitions download -c house-prices-advanced-regression-techniques
!unzip house-prices-advanced-regression-techniques.zip

# === Step 5: Load the Data ===
import pandas as pd

df = pd.read_csv('train.csv')
print(df[['GrLivArea', 'BedroomAbvGr', 'FullBath', 'SalePrice']].head())

# === Step 6: Data Preprocessing ===
features = ['GrLivArea', 'BedroomAbvGr', 'FullBath']
target = 'SalePrice'

# Drop rows with missing values in the selected columns
df = df[features + [target]].dropna()

# Define X and y
X = df[features]
y = df[target]

# === Step 7: Train-Test Split ===
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# === Step 8: Train Linear Regression Model ===
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

# === Step 9: Evaluate the Model ===
from sklearn.metrics import mean_squared_error, r2_score

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"RÂ² Score: {r2}")

# === Step 10: Visualize Predictions ===
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel('Actual SalePrice')
plt.ylabel('Predicted SalePrice')
plt.title('Linear Regression: Actual vs. Predicted SalePrice')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Line of perfect prediction
plt.show()
